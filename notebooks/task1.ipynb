{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f46da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\kaimtenx\\week22\\bank-review-analysis\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google_play_scraper import Sort, reviews\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from langdetect import detect\n",
    "from deep_translator import GoogleTranslator\n",
    "from transformers import pipeline\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4ceaa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data folder\n",
    "os.makedirs(\"../data\", exist_ok=True)\n",
    "\n",
    "# Updated app IDs\n",
    "bank_ids = {\n",
    "    \"cbe\": \"com.combanketh.mobilebanking\",\n",
    "    \"absiniya\": \"com.boa.boaMobileBanking\",\n",
    "    \"dashin\": \"com.dashen.dashensuperapp\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5aa41624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Scraping CBE...\n",
      "✅ cbe: 43 reviews collected\n",
      "✅ cbe: 98 reviews collected\n",
      "✅ cbe: 151 reviews collected\n",
      "✅ cbe: 201 reviews collected\n",
      "✅ cbe: 247 reviews collected\n",
      "✅ cbe: 300 reviews collected\n",
      "✅ cbe: 355 reviews collected\n",
      "✅ cbe: 411 reviews collected\n",
      "✅ cbe: 450 reviews collected\n",
      "💾 Saved to ../data/cbe.csv\n",
      "\n",
      "🔍 Scraping ABSINIYA...\n",
      "✅ absiniya: 64 reviews collected\n",
      "✅ absiniya: 126 reviews collected\n",
      "✅ absiniya: 186 reviews collected\n",
      "✅ absiniya: 241 reviews collected\n",
      "✅ absiniya: 296 reviews collected\n",
      "✅ absiniya: 357 reviews collected\n",
      "✅ absiniya: 431 reviews collected\n",
      "✅ absiniya: 450 reviews collected\n",
      "💾 Saved to ../data/absiniya.csv\n",
      "\n",
      "🔍 Scraping DASHIN...\n",
      "✅ dashin: 54 reviews collected\n",
      "✅ dashin: 148 reviews collected\n",
      "✅ dashin: 214 reviews collected\n",
      "✅ dashin: 277 reviews collected\n",
      "✅ dashin: 314 reviews collected\n",
      " No more reviews available.\n",
      "💾 Saved to ../data/dashin.csv\n"
     ]
    }
   ],
   "source": [
    "# Filter function: keep only Amharic or English\n",
    "def is_am_or_en(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        return lang in ['am', 'en']\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Scraper function\n",
    "def scrape_400_reviews(app_id, bank_name, target_count=450):\n",
    "    print(f\"\\n🔍 Scraping {bank_name.upper()}...\")\n",
    "\n",
    "    all_reviews = []\n",
    "    seen = set()\n",
    "    token = None\n",
    "\n",
    "    while len(all_reviews) < target_count:\n",
    "        rvws, token = reviews(\n",
    "            app_id,\n",
    "            lang='en',\n",
    "            country='et',\n",
    "            sort=Sort.NEWEST,\n",
    "            count=100,\n",
    "            continuation_token=token\n",
    "        )\n",
    "\n",
    "        if not rvws:\n",
    "            print(\" No more reviews available.\")\n",
    "            break\n",
    "\n",
    "        for r in rvws:\n",
    "            content = r['content']\n",
    "            if content in seen or not is_am_or_en(content):\n",
    "                continue\n",
    "\n",
    "            seen.add(content)\n",
    "            all_reviews.append({\n",
    "                'review': content,\n",
    "                'rating': r['score'],\n",
    "                'date': r['at'],\n",
    "                'bank': bank_name.capitalize(),\n",
    "                'source': 'Google Play'\n",
    "            })\n",
    "\n",
    "            if len(all_reviews) >= target_count:\n",
    "                break\n",
    "\n",
    "        print(f\"✅ {bank_name}: {len(all_reviews)} reviews collected\")\n",
    "\n",
    "        if token is None:\n",
    "            break\n",
    "\n",
    "        time.sleep(1)  # polite pause\n",
    "\n",
    "    df = pd.DataFrame(all_reviews)\n",
    "    df.to_csv(f\"../data/{bank_name}.csv\", index=False)\n",
    "    print(f\"💾 Saved to ../data/{bank_name}.csv\")\n",
    "    return df\n",
    "# Run for all banks\n",
    "for bank, app_id in bank_ids.items():\n",
    "    scrape_400_reviews(app_id, bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99e3a0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Total missing values (all banks):\n",
      "review    0\n",
      "rating    0\n",
      "date      0\n",
      "bank      0\n",
      "source    0\n",
      "dtype: int64\n",
      "\n",
      "🔁 Total duplicate reviews (by review + bank): 0\n",
      "\n",
      " Dropped 0 rows with missing/empty review.\n",
      "\n",
      " Final review count per bank after cleaning:\n",
      "bank\n",
      "Cbe         450\n",
      "Absiniya    450\n",
      "Dashin      314\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Cleaned data saved to: ../data/BANKS_review.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load scraped CSVs\n",
    "cbe = pd.read_csv(\"../data/cbe.csv\")\n",
    "boa = pd.read_csv(\"../data/absiniya.csv\")\n",
    "dashin = pd.read_csv(\"../data/dashin.csv\")\n",
    "# Step 2: Combine into one DataFrame\n",
    "df = pd.concat([cbe, boa, dashin], ignore_index=True)\n",
    "\n",
    "# Step 3: Ensure required columns\n",
    "df = df[['review', 'rating', 'date', 'bank', 'source']]\n",
    "\n",
    "# Step 4: Print overall missing values\n",
    "print(\"🔍 Total missing values (all banks):\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Step 5: Print overall duplicates\n",
    "total_dups = df.duplicated(subset=['review', 'bank']).sum()\n",
    "print(f\"\\n🔁 Total duplicate reviews (by review + bank): {total_dups}\")\n",
    "\n",
    "# Step 6: Drop rows where 'review' is missing or empty\n",
    "before = df.shape[0]\n",
    "df = df[df['review'].notna()]\n",
    "df = df[df['review'].str.strip() != '']\n",
    "after = df.shape[0]\n",
    "print(f\"\\n Dropped {before - after} rows with missing/empty review.\")\n",
    "\n",
    "# Step 7: Remove duplicates per bank\n",
    "df = df.drop_duplicates(subset=['review', 'bank'])\n",
    "\n",
    "# Step 8: Final counts per bank\n",
    "print(\"\\n Final review count per bank after cleaning:\")\n",
    "print(df['bank'].value_counts())\n",
    "\n",
    "# Step 9: Save cleaned data\n",
    "df.to_csv(\"../data/BANKS_review.csv\", index=False)\n",
    "print(\"\\n Cleaned data saved to: ../data/BANKS_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "116aada9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# language detection and translation into english\n",
    "from langdetect import detect\n",
    "from deep_translator import GoogleTranslator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d09a07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔁 Translating reviews (this may take several minutes)...\n",
      "✅ Translated reviews saved to: ../data/BANKS_review_translated.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load cleaned reviews\n",
    "df = pd.read_csv(\"../data/BANKS_review.csv\")\n",
    "\n",
    "# Step 2: Translation function\n",
    "def translate_to_english(text):\n",
    "    try:\n",
    "        lang = detect(text)\n",
    "        if lang == 'am':\n",
    "            translated = GoogleTranslator(source='auto', target='en').translate(text)\n",
    "            return translated\n",
    "        elif lang == 'en':\n",
    "            return text  # Already in English\n",
    "        else:\n",
    "            return \"UNTRANSLATED\"\n",
    "    except Exception as e:\n",
    "        return \"UNTRANSLATED\"\n",
    "\n",
    "# Step 3: Translate Amharic reviews only\n",
    "print(\"🔁 Translating reviews (this may take several minutes)...\")\n",
    "df['translated_review'] = df['review'].apply(translate_to_english)\n",
    "\n",
    "# Step 4: Save translated dataset\n",
    "df.to_csv(\"../data/BANKS_review_translated.csv\", index=False)\n",
    "print(\"✅ Translated reviews saved to: ../data/BANKS_review_translated.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6d4717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1182/1182 [00:03<00:00, 320.11it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(str(text))\n",
    "    except:\n",
    "        return 'unknown'\n",
    "\n",
    "df['lang_detected'] = df['translated_review'].progress_apply(detect_language)\n",
    "df = df[df['lang_detected'] == 'en']\n",
    "df.to_csv(\"../data/BANKS_review_translatedENGLISH.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad19f724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from langdetect.lang_detect_exception import LangDetectException\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23689ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Detecting languages in translated reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1175/1175 [00:03<00:00, 306.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🌐 Language Distribution in translated_review:\n",
      "en: 1170 reviews\n",
      "af: 3 reviews\n",
      "so: 1 reviews\n",
      "de: 1 reviews\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Enable progress bar for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"../data/BANKS_review_translatedENGLISH.csv\")  # or your translated file\n",
    "\n",
    "# Language detection function\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(str(text))\n",
    "    except LangDetectException:\n",
    "        return 'unknown'\n",
    "\n",
    "# Detect language of each translated review\n",
    "print(\"🔍 Detecting languages in translated reviews...\")\n",
    "df['lang_detected'] = df['translated_review'].progress_apply(detect_language)\n",
    "\n",
    "# Count each language\n",
    "lang_counts = Counter(df['lang_detected'])\n",
    "\n",
    "# Print result\n",
    "print(\"\\n🌐 Language Distribution in translated_review:\")\n",
    "for lang, count in lang_counts.items():\n",
    "    print(f\"{lang}: {count} reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b45f5270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaned dataset saved to: ../data/translated_allbanksdata_cleaned.csv\n",
      "Remaining English reviews: 1175\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/BANKS_review_translatedENGLISH.csv\")  # or your translated file# Keep only rows where language is English\n",
    "english_only_df = df[df['lang_detected'] == 'en']\n",
    "\n",
    "# Save cleaned data\n",
    "english_only_df.to_csv(\"../data/translated_allbanksdata_cleaned.csv\", index=False)\n",
    "print(f\" Cleaned dataset saved to: ../data/translated_allbanksdata_cleaned.csv\")\n",
    "print(f\"Remaining English reviews: {english_only_df.shape[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
